{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36CtFCromX73"
      },
      "outputs": [],
      "source": [
        "# Main imports\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import math\n",
        "%matplotlib inline\n",
        "from importlib import reload\n",
        "import utils2; reload(utils2)\n",
        "from utils2 import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIvpniienc5a",
        "outputId": "56a945ca-343c-4856-d39e-5830dcccc811"
      },
      "outputs": [],
      "source": [
        "test_imgs_dir = \"test_img\"\n",
        "test_imgs_paths = glob.glob(test_imgs_dir + \"/*.jpg\")\n",
        "test_img_names = np.asarray(list(map(lambda img_path: img_path.split(\"/\")[-1].split(\".\")[0], test_imgs_paths)))\n",
        "undist_test_img_names = np.asarray(list(map(lambda img_name: \"{0}{1}\".format(\"undistorted_\", img_name), test_img_names)))\n",
        "test_imgs = np.asarray(list(map(lambda img_path: load_image(img_path), test_imgs_paths)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ubxTVrcnnS1"
      },
      "outputs": [],
      "source": [
        "# FINAL FUNCTIONS\n",
        "def threshold_img(img, channel, thres=(0, 255)):\n",
        "    \"\"\"\n",
        "    Applies a threshold mask to the input image\n",
        "    \"\"\"\n",
        "    img_ch = img[:,:,channel]\n",
        "    if thres is None:\n",
        "        return img_ch\n",
        "\n",
        "    mask_ch = np.zeros_like(img_ch)\n",
        "    mask_ch[ (thres[0] <= img_ch) & (thres[1] >= img_ch) ] = 1\n",
        "    return mask_ch\n",
        "\n",
        "\n",
        "def compute_hsv_white_red_binary(rgb_img):\n",
        "    \"\"\"\n",
        "    Returns a binary thresholded image produced retaining only white and yellow elements on the picture\n",
        "    The provided image should be in RGB format\n",
        "    \"\"\"\n",
        "    hsv_img = to_hsv(rgb_img)\n",
        "\n",
        "    # Red color thresholds\n",
        "    red_hue_min = int(0 * 179)  # Lower bound for red hue\n",
        "    red_hue_max = int(179)  # Upper bound for red hue (allowing some range)\n",
        "    red_saturation_min = int(0.5 * 255)  # Lower bound for red saturation\n",
        "    red_saturation_max = int(1.0 * 255)  # Upper bound for red saturation\n",
        "    red_value_min = int(0.5 * 255)  # Lower bound for red value\n",
        "    red_value_max = int(1 * 255)  # Upper bound for red value\n",
        "\n",
        "    img_hsv_red_bin = np.zeros_like(hsv_img[:,:,0])\n",
        "    img_hsv_red_bin[((hsv_img[:,:,0] >= red_hue_min) & (hsv_img[:,:,0] <= red_hue_max))\n",
        "                    & ((hsv_img[:,:,1] >= red_saturation_min) & (hsv_img[:,:,1] <= red_saturation_max))\n",
        "                    & ((hsv_img[:,:,2] >= red_value_min) & (hsv_img[:,:,2] <= red_value_max))] = 1\n",
        "\n",
        "    # White color thresholds\n",
        "    white_saturation_max = int(0.3 * 255)  # Adjusted saturation maximum for white\n",
        "    white_value_min = int(0.9 * 255)  # Adjusted value minimum for white\n",
        "\n",
        "    img_hsv_white_bin = np.zeros_like(hsv_img[:,:,0])\n",
        "    img_hsv_white_bin[((hsv_img[:,:,1] <= white_saturation_max))\n",
        "                      & ((hsv_img[:,:,2] >= white_value_min))] = 1\n",
        "\n",
        "    # Combine both red and white binary images\n",
        "    img_hls_white_red_bin = np.zeros_like(hsv_img[:,:,0])\n",
        "    img_hls_white_red_bin[(img_hsv_red_bin == 1) | (img_hsv_white_bin == 1)] = 1\n",
        "\n",
        "    return img_hls_white_red_bin\n",
        "\n",
        "\n",
        "\n",
        "def abs_sobel(gray_img, x_dir=True, kernel_size=3, thres=(0, 255)):\n",
        "    \"\"\"\n",
        "    Applies the sobel operator to a grayscale-like (i.e. single channel) image in either horizontal or vertical direction\n",
        "    The function also computes the asbolute value of the resulting matrix and applies a binary threshold\n",
        "    \"\"\"\n",
        "    sobel = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, ksize=kernel_size) if x_dir else cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
        "    sobel_abs = np.absolute(sobel)\n",
        "    sobel_scaled = np.uint8(255 * sobel / np.max(sobel_abs))\n",
        "    gradient_mask = np.zeros_like(sobel_scaled)\n",
        "    gradient_mask[(thres[0] <= sobel_scaled) & (sobel_scaled <= thres[1])] = 1\n",
        "    return gradient_mask\n",
        "\n",
        "def mag_sobel(gray_img, kernel_size=3, thres=(0, 255)):\n",
        "    \"\"\"\n",
        "    Computes sobel matrix in both x and y directions, merges them by computing the magnitude in both directions\n",
        "    and applies a threshold value to only set pixels within the specified range\n",
        "    \"\"\"\n",
        "    sx = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
        "    sy = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
        "\n",
        "    sxy = np.sqrt(np.square(sx) + np.square(sy))\n",
        "    scaled_sxy = np.uint8(255 * sxy / np.max(sxy))\n",
        "\n",
        "    sxy_binary = np.zeros_like(scaled_sxy)\n",
        "    sxy_binary[(scaled_sxy >= thres[0]) & (scaled_sxy <= thres[1])] = 1\n",
        "\n",
        "    return sxy_binary\n",
        "def dir_sobel(gray_img, kernel_size=3, thres=(0, np.pi/2)):\n",
        "    \"\"\"\n",
        "    Computes sobel matrix in both x and y directions, gets their absolute values to find the direction of the gradient\n",
        "    and applies a threshold value to only set pixels within the specified range\n",
        "    \"\"\"\n",
        "    sx_abs = np.absolute(cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, ksize=kernel_size))\n",
        "    sy_abs = np.absolute(cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, ksize=kernel_size))\n",
        "\n",
        "    dir_sxy = np.arctan2(sx_abs, sy_abs)\n",
        "\n",
        "    binary_output = np.zeros_like(dir_sxy)\n",
        "    binary_output[(dir_sxy >= thres[0]) & (dir_sxy <= thres[1])] = 1\n",
        "\n",
        "    return binary_output\n",
        "def combined_sobels(sx_binary, sy_binary, sxy_magnitude_binary, gray_img, kernel_size=3, angle_thres=(0, np.pi/2)):\n",
        "    sxy_direction_binary = dir_sobel(gray_img, kernel_size=kernel_size, thres=angle_thres)\n",
        "\n",
        "    combined = np.zeros_like(sxy_direction_binary)\n",
        "    # Sobel X returned the best output so we keep all of its results. We perform a binary and on all the other sobels\n",
        "    combined[(sx_binary == 1) | ((sy_binary == 1) & (sxy_magnitude_binary == 1) & (sxy_direction_binary == 1))] = 1\n",
        "\n",
        "    return combined\n",
        "def compute_perspective_transform_matrices(src, dst):\n",
        "    \"\"\"\n",
        "    Returns the tuple (M, M_inv) where M represents the matrix to use for perspective transform\n",
        "    and M_inv is the matrix used to revert the transformed image back to the original one\n",
        "    \"\"\"\n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
        "\n",
        "    return (M, M_inv)\n",
        "\n",
        "def perspective_transform(img, src, dst):\n",
        "    \"\"\"\n",
        "    Applies a perspective\n",
        "    \"\"\"\n",
        "    M = cv2.getPerspectiveTransform(src, dst)\n",
        "    img_size = (img.shape[1], img.shape[0])\n",
        "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
        "\n",
        "    return warped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXRYd0c7YtK_"
      },
      "outputs": [],
      "source": [
        "test_img_path = test_imgs_paths[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA6UzEiEoQDm"
      },
      "outputs": [],
      "source": [
        "test_img = load_image(test_img_path)\n",
        "outside_test_img_path = test_imgs_paths[0]\n",
        "outside_test_img = load_image(outside_test_img_path)\n",
        "rgb_comp = np.asarray([[threshold_img(test_img, 0, thres=None), threshold_img(test_img, 1, thres=None), threshold_img(test_img, 2, thres=None)]])\n",
        "rgb_lbs = np.asarray([[\"Red Channel\", \"Green Channel\", \"Blue Channel\"]])\n",
        "hls_test_img = to_hls(test_img)\n",
        "hls_comp = np.asarray([[threshold_img(hls_test_img, 0, thres=None), threshold_img(hls_test_img, 1, thres=None), threshold_img(hls_test_img, 2, thres=None)]])\n",
        "hls_lbs = np.asarray([[\"Hue Channel\", \"Lightness Channel\", \"Saturation Channel\"]])\n",
        "hsv_test_img = to_hsv(test_img)\n",
        "hsv_comp = np.asarray([[threshold_img(hsv_test_img, 0, thres=None), threshold_img(hsv_test_img, 1, thres=None), threshold_img(hsv_test_img, 2, thres=None)]])\n",
        "hsv_lbs = np.asarray([[\"Hue Channel\", \"Saturation Channel\", \"Value Channel\"]])\n",
        "lab_test_img = to_lab(test_img)\n",
        "lab_comp = np.asarray([[threshold_img(lab_test_img, 0, thres=None), threshold_img(lab_test_img, 1, thres=None), threshold_img(lab_test_img, 2, thres=None)]])\n",
        "lab_lbs = np.asarray([[\"Lightness Channel\", \"Green-Red (A) Channel\", \"Blue-Yellow (B) Channel\"]])\n",
        "color_spaces_comps = np.concatenate((rgb_comp, hls_comp, hsv_comp, lab_comp))\n",
        "color_spaces_lbs = np.concatenate((rgb_lbs, hls_lbs, hsv_lbs, lab_lbs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBsHpo_78PCC"
      },
      "outputs": [],
      "source": [
        "white_red_hsv_img_bin = compute_hsv_white_red_binary(test_img)\n",
        "\n",
        "# fig, ax = plt.subplots(1, 2, figsize=(10,7))\n",
        "# ax[0].imshow(test_img)\n",
        "# ax[0].axis(\"off\")\n",
        "# ax[0].set_title(\"Undistorted Image\")\n",
        "\n",
        "# ax[1].imshow(undistorted_yellow_white_hsv_img_bin, cmap='gray')\n",
        "# ax[1].axis(\"off\")\n",
        "# ax[1].set_title(\"HSV Color Thresholded Image\")\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "# _________________ Params 1 _________________\n",
        "\n",
        "# hls_test_img threshold_img(hls_test_img, 2, thres=None)\n",
        "# hsv_test_img threshold_img(hsv_test_img, 1, thres=None)\n",
        "# lab_test_img threshold_img(lab_test_img, 1, thres=None)\n",
        "hls_test_img = to_hls(test_img)\n",
        "hsv_test_img = to_hsv(test_img)\n",
        "lab_test_img = to_lab(test_img)\n",
        "\n",
        "hls_image = threshold_img(hls_test_img, 2, thres=None)\n",
        "hsv_image = threshold_img(hsv_test_img, 1, thres=None)\n",
        "lab_image = threshold_img(lab_test_img, 1, thres=None)\n",
        "\n",
        "# threshold_image = hsv_image\n",
        "# threshold_image = hls_image\n",
        "threshold_image = lab_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ivn1SmlNpDx6",
        "outputId": "f837a602-2f07-4072-ac66-2ecad7d34904"
      },
      "outputs": [],
      "source": [
        "# _________ Params 2 _____________\n",
        "sobx_11x11_thres = np.asarray([[abs_sobel(threshold_image, kernel_size=11, thres=(20, 120)), abs_sobel(threshold_image, kernel_size=11, thres=(50, 150)), abs_sobel(threshold_image, kernel_size=11, thres=(80, 200))]])\n",
        "sobx_15x15_thres = np.asarray([[abs_sobel(threshold_image, kernel_size=15, thres=(20, 120)), abs_sobel(threshold_image, kernel_size=15, thres=(50, 150)), abs_sobel(threshold_image, kernel_size=15, thres=(80, 200))]])\n",
        "\n",
        "\n",
        "sobx_11x11_thres_lbs = np.asarray([[\"11x11 - Threshold (20,120)\", \"11x11 - Threshold (50,150)\", \"11x11 - Threshold (80,200)\"]])\n",
        "sobx_15x15_thres_lbs = np.asarray([[\"15x15 - Threshold (20,120)\", \"15x15 - Threshold (50,150)\", \"15x15 - Threshold (80,200)\"]])\n",
        "sobx_thres = np.concatenate(( sobx_11x11_thres, sobx_15x15_thres))\n",
        "sobx_thres_lbs = np.concatenate((sobx_11x11_thres_lbs, sobx_15x15_thres_lbs))\n",
        "\n",
        "\n",
        "\n",
        "sobx_best = abs_sobel(threshold_image, kernel_size=15, thres=(80, 200))\n",
        "show_image_list(sobx_thres, sobx_thres_lbs, \"Sobel (X Direction) Thresholds\", cols=3, show_ticks=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sfGJ-NzHpMdA",
        "outputId": "ee30d7c9-e045-49c0-e8ab-d3df5213c88a"
      },
      "outputs": [],
      "source": [
        "# ___________ Perams 3 _____________\n",
        "\n",
        "soby_11x11_thres = np.asarray([[abs_sobel(threshold_image, x_dir=False, kernel_size=11, thres=(20, 120)), abs_sobel(threshold_image, x_dir=False, kernel_size=11, thres=(50, 150)), abs_sobel(threshold_image, x_dir=False, kernel_size=11, thres=(80, 200))]])\n",
        "soby_15x15_thres = np.asarray([[abs_sobel(threshold_image, x_dir=False, kernel_size=15, thres=(20, 120)), abs_sobel(threshold_image, x_dir=False, kernel_size=15, thres=(50, 150)), abs_sobel(threshold_image, x_dir=False, kernel_size=15, thres=(80, 200))]])\n",
        "\n",
        "soby_11x11_thres_lbs = np.asarray([[\"11x11 - Threshold (20,120)\", \"11x11 - Threshold (50,150)\", \"11x11 - Threshold (80,200)\"]])\n",
        "soby_15x15_thres_lbs = np.asarray([[\"15x15 - Threshold (20,120)\", \"15x15 - Threshold (50,150)\", \"15x15 - Threshold (80,200)\"]])\n",
        "soby_thres = np.concatenate((soby_11x11_thres, soby_15x15_thres))\n",
        "soby_thres_lbs = np.concatenate((soby_11x11_thres_lbs, soby_15x15_thres_lbs))\n",
        "\n",
        "soby_best = abs_sobel(threshold_image, x_dir=False, kernel_size=11, thres=(50, 150))\n",
        "show_image_list(soby_thres, soby_thres_lbs, \"Sobel (Y Direction) Thresholds\", cols=3, show_ticks=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4Ve999PUpWtP",
        "outputId": "07498435-90dc-485f-d425-f1c23394e4bf"
      },
      "outputs": [],
      "source": [
        "# ________ perams 3 _________\n",
        "sobxy_11x11_thres = np.asarray([[mag_sobel(threshold_image, kernel_size=11, thres=(20, 80)), mag_sobel(threshold_image, kernel_size=11, thres=(50, 150)), mag_sobel(threshold_image, kernel_size=11, thres=(80, 200))]])\n",
        "sobxy_15x15_thres = np.asarray([[mag_sobel(threshold_image, kernel_size=15, thres=(20, 80)), mag_sobel(threshold_image, kernel_size=15, thres=(50, 150)), mag_sobel(threshold_image, kernel_size=15, thres=(80, 200))]])\n",
        "\n",
        "sobxy_11x11_thres_lbs = np.asarray([[\"11x11 - Threshold (20,80)\", \"11x11 - Threshold (50,150)\", \"11x11 - Threshold (80,200)\"]])\n",
        "sobxy_15x15_thres_lbs = np.asarray([[\"15x15 - Threshold (20,80)\", \"15x15 - Threshold (50,150)\", \"15x15 - Threshold (80,200)\"]])\n",
        "sobxy_thres = np.concatenate((sobxy_11x11_thres, sobxy_15x15_thres))\n",
        "sobxy_thres_lbs = np.concatenate((sobxy_11x11_thres_lbs, sobxy_15x15_thres_lbs))\n",
        "\n",
        "sobxy_best = mag_sobel(threshold_image, kernel_size=15, thres=(80, 200))\n",
        "show_image_list(sobxy_thres, sobxy_thres_lbs, \"Sobel (XY Magnitude) Thresholds\", cols=3, show_ticks=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rltnBK6WpdX1",
        "outputId": "16120178-b91d-4b03-fedb-ff81665f2382"
      },
      "outputs": [],
      "source": [
        "# ___________ Perams 4 ______________\n",
        "\n",
        "sobxy_combined_dir_11x11_thres = np.asarray([[combined_sobels(sobx_best, soby_best, sobxy_best, threshold_image, kernel_size=11, angle_thres=(0, np.pi/4)),\n",
        "                                            combined_sobels(sobx_best, soby_best, sobxy_best, threshold_image, kernel_size=11, angle_thres=(np.pi/4, np.pi/2)),\n",
        "                                            combined_sobels(sobx_best, soby_best, sobxy_best, threshold_image, kernel_size=11, angle_thres=(np.pi/3, np.pi/2))\n",
        "                                           ]])\n",
        "\n",
        "sobxy_combined_dir_15x15_thres = np.asarray([[combined_sobels(sobx_best, soby_best, sobxy_best, threshold_image, kernel_size=15, angle_thres=(0, np.pi/4)),\n",
        "                                            combined_sobels(sobx_best, soby_best, sobxy_best, threshold_image, kernel_size=15, angle_thres=(np.pi/4, np.pi/2)),\n",
        "                                            combined_sobels(sobx_best, soby_best, sobxy_best, threshold_image, kernel_size=15, angle_thres=(np.pi/3, np.pi/2))\n",
        "                                           ]])\n",
        "\n",
        "\n",
        "sobxy_combined_dir_11x11_thres_lbs = np.asarray([[\"11x11 - Combined (0, pi/4)\", \"11x11 - Combined (pi/4, pi/2)\", \"11x11 - Combined (pi/3, pi/2)\"]])\n",
        "sobxy_combined_dir_15x15_thres_lbs = np.asarray([[\"15x15 - Combined (0, pi/4)\", \"15x15 - Combined (pi/4, pi/2)\", \"15x15 - Combined (pi/3, pi/2)\"]])\n",
        "sobxy_combined_dir_thres = np.concatenate((sobxy_combined_dir_11x11_thres, sobxy_combined_dir_15x15_thres))\n",
        "sobxy_combined_dir_thres_lbs = np.concatenate((sobxy_combined_dir_11x11_thres_lbs, sobxy_combined_dir_15x15_thres_lbs))\n",
        "\n",
        "\n",
        "sobel_combined_best = combined_sobels(sobx_best, soby_best, sobxy_best, threshold_image, kernel_size=15, angle_thres=(0, np.pi/4))\n",
        "show_image_list(sobxy_combined_dir_thres, sobxy_combined_dir_thres_lbs, \"Combined With Gradient Direction\", cols=3, show_ticks=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "KBtcyAg5pr_F",
        "outputId": "cd46ad3c-a92c-46a0-f8c0-6ff31988b964"
      },
      "outputs": [],
      "source": [
        "color_binary = np.dstack((np.zeros_like(sobel_combined_best), sobel_combined_best, white_red_hsv_img_bin)) * 255\n",
        "color_binary = color_binary.astype(np.uint8)\n",
        "combined_binary = np.zeros_like(white_red_hsv_img_bin)\n",
        "combined_binary[(sobel_combined_best == 1) | (white_red_hsv_img_bin == 1)] = 1\n",
        "combined_binaries = [[color_binary, combined_binary]]\n",
        "combined_binaries_lbs = np.asarray([[\"Stacked Thresholds\", \"Combined Color And Gradient Thresholds\"]])\n",
        "show_image_list(combined_binaries, combined_binaries_lbs, \"Color And Binary Combined Gradient And HLS (S) Thresholss\", cols=2, fig_size=(17, 6), show_ticks=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9ZOvDP5ihZD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_combined_binary_thresholded_img(img):\n",
        "    \"\"\"\n",
        "    Applies a combination of binary Sobel and color thresholding to an undistorted image\n",
        "    Those binary images are then combined to produce the returned binary image\n",
        "    \"\"\"\n",
        "    #Peramiter one\n",
        "    # thresholded_img = threshold_img(img, 2, thres=None)\n",
        "    threshold_image = threshold_img(img, 1, thres=None)\n",
        "\n",
        "    #Peramiter two\n",
        "    sobx_best = abs_sobel(threshold_image, kernel_size=15, thres=(80, 200))\n",
        "\n",
        "    #Peramiter three\n",
        "    soby_best = abs_sobel(threshold_image, x_dir=False, kernel_size=11, thres=(50, 150))\n",
        "\n",
        "    #Peramiter four\n",
        "    sobxy_best = mag_sobel(threshold_image, kernel_size=15, thres=(80, 200))\n",
        "\n",
        "    #Peramiter five\n",
        "    sobel_combined_best = combined_sobels(sobx_best, soby_best, sobxy_best, threshold_image, kernel_size=15, angle_thres=(0, np.pi/4))\n",
        "\n",
        "\n",
        "    hsv_w_y_thres = compute_hsv_white_red_binary(img)\n",
        "    combined_binary = np.zeros_like(hsv_w_y_thres)\n",
        "    combined_binary[(sobel_combined_best == 1) | (hsv_w_y_thres == 1)] = 1\n",
        "\n",
        "\n",
        "    # return sxy_combined_dir #DEBUG UNCOMMENT\n",
        "    return combined_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "G-vqy8CApzhm",
        "outputId": "27fb259c-4974-4868-f4d6-3e042502cd6e"
      },
      "outputs": [],
      "source": [
        "copy_combined = np.copy(test_imgs[1])\n",
        "(bottom_px, right_px) = (copy_combined.shape[0] - 1, copy_combined.shape[1] - 1)\n",
        "pts = np.array([[25,430],[375,345],[660,345], [right_px-20, 420]], np.int32)\n",
        "cv2.polylines(copy_combined,[pts],True,(255,0,0), 10)\n",
        "plt.axis('off')\n",
        "plt.imshow(copy_combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "X-PzWf4Bp8Ek",
        "outputId": "1591eb7e-72b1-4b30-a323-35ee9b86f0a5"
      },
      "outputs": [],
      "source": [
        "src_pts = pts.astype(np.float32)\n",
        "dst_pts = np.array([[200, bottom_px], [200, 0], [right_px-200, 0], [right_px-200, bottom_px]], np.float32)\n",
        "test_img_persp_tr = perspective_transform(test_imgs[3], src_pts, dst_pts)\n",
        "plt.imshow(test_img_persp_tr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "f0QAYlOVDrdV",
        "outputId": "dd74af5a-1206-4600-93e6-acb53bd79c08"
      },
      "outputs": [],
      "source": [
        "pts = np.array([[25,430],[375,345],[660,345], [right_px-20, 420]], np.int32)\n",
        "src_pts = pts.astype(np.float32)\n",
        "dst_pts = np.array([[200, bottom_px], [200, 0], [right_px-200, 0], [right_px-200, bottom_px]], np.float32)\n",
        "per_img = perspective_transform(test_imgs[1], src_pts, dst_pts)\n",
        "plt.imshow(per_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "fYx9cuS_qAY-",
        "outputId": "cc4e43d7-92c0-4ae6-9576-184d76e93f21"
      },
      "outputs": [],
      "source": [
        "test_imgs_pers_tr = np.asarray(list(map(lambda img: perspective_transform(img, src_pts, dst_pts), test_imgs)))\n",
        "test_persp_img = np.copy(test_imgs_pers_tr[1])\n",
        "dst = dst_pts.astype(np.int32)\n",
        "cv2.polylines(test_persp_img,[dst],True,(255,0,0), 10)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15,10))\n",
        "ax[0].imshow(test_imgs_pers_tr[1])\n",
        "ax[0].set_title(\"Perspecting Transform - Curved Lines\")\n",
        "\n",
        "ax[1].imshow(test_imgs[1])\n",
        "ax[1].set_title(\"Perspective Transform - Straight Lines\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W5fl7ho3qDnO",
        "outputId": "dff7b179-d0c6-4843-9b94-24cda99a974e"
      },
      "outputs": [],
      "source": [
        "test_undist_imgs_and_p_tr = np.asarray(list(zip(test_imgs, test_imgs_pers_tr)))\n",
        "test_undist_imgs_and_p_tr_names = np.asarray(list(zip(undist_test_img_names, undist_test_img_names)))\n",
        "show_image_list(test_undist_imgs_and_p_tr, test_undist_imgs_and_p_tr_names, \"Undistorted and Birds View Image\", fig_size=(15, 20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QKpxunhBaHpj",
        "outputId": "090a6f03-e1d9-4c49-d511-64d96e181005"
      },
      "outputs": [],
      "source": [
        "test_imgs_thresholded = np.asarray(list(map(lambda img: get_combined_binary_thresholded_img(img), test_imgs)))\n",
        "test_imgs_and_thresholded = np.asarray(list(zip(test_imgs, test_imgs_thresholded)))\n",
        "test_imgs_and_thresholded_names = np.asarray(list(zip(undist_test_img_names, undist_test_img_names)))\n",
        "show_image_list(test_imgs_and_thresholded, test_imgs_and_thresholded_names, \"Undistorted and Birds View Image\", fig_size=(15, 20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j8TJSzoJqJzH",
        "outputId": "cdeb55e7-2ee8-4fc1-ea09-14eb80cba5ef"
      },
      "outputs": [],
      "source": [
        "test_imgs_combined_binary_thres = np.asarray(list(map(lambda img: get_combined_binary_thresholded_img(img), test_imgs)))\n",
        "test_imgs_psp_tr = np.asarray(list(map(lambda img: perspective_transform(img, src_pts, dst_pts), test_imgs)))\n",
        "test_imgs_combined_binary_psp_tr = np.asarray(list(map(lambda img: perspective_transform(img, src_pts, dst_pts), test_imgs_combined_binary_thres)))\n",
        "test_imgs_combined_binary_and_psp_tr = np.asarray(list(zip(test_imgs_psp_tr[0],test_imgs_combined_binary_thres, test_imgs_combined_binary_psp_tr)))\n",
        "test_imgs_combined_binary_and_psp_tr_names = np.asarray(list(zip(undist_test_img_names,undist_test_img_names, undist_test_img_names)))\n",
        "show_image_list(test_imgs_combined_binary_and_psp_tr, test_imgs_combined_binary_and_psp_tr_names, \"Combined Binary And Perspective Transform Images\", cols=3, fig_size=(15, 15))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "i3hcWmLJqPyL",
        "outputId": "9d2998ba-2003-404e-f555-12edcab3be14"
      },
      "outputs": [],
      "source": [
        "img_example = test_imgs_combined_binary_and_psp_tr[3][2]\n",
        "histogram = np.sum(img_example[img_example.shape[0]//2:,:], axis=0)\n",
        "kernel_width = 30\n",
        "smoothing_kernel = np.ones(kernel_width) / kernel_width\n",
        "\n",
        "# Apply convolution to smooth the histogram\n",
        "smoothed_histogram = np.convolve(histogram, smoothing_kernel, mode='same')\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15,4))\n",
        "ax[0].imshow(img_example, cmap='gray')\n",
        "ax[0].axis(\"off\")\n",
        "ax[0].set_title(\"Binary Thresholded Perspective Transform Image\")\n",
        "\n",
        "ax[1].plot(smoothed_histogram)\n",
        "ax[1].set_title(\"Histogram Of Pixel Intensities (Image Bottom Half)\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrEXaiwK2_by"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "import math\n",
        "\n",
        "class LaneLineHistory:\n",
        "    def __init__(self, queue_depth=2, test_points=[50, 300, 500, 700], poly_max_deviation_distance=150):\n",
        "        self.lane_lines = create_queue(queue_depth)\n",
        "        self.smoothed_poly = None\n",
        "        self.test_points = test_points\n",
        "        self.poly_max_deviation_distance = poly_max_deviation_distance\n",
        "\n",
        "    def append(self, lane_line, force=False):\n",
        "        if len(self.lane_lines) == 0 or force:\n",
        "            self.lane_lines.append(lane_line)\n",
        "            self.get_smoothed_polynomial()\n",
        "            return True\n",
        "\n",
        "        test_y_smooth = np.asarray(list(map(lambda x: self.smoothed_poly[0] * x**2 + self.smoothed_poly[1] * x + self.smoothed_poly[2], self.test_points)))\n",
        "        test_y_new = np.asarray(list(map(lambda x: lane_line.polynomial_coeff[0] * x**2 + lane_line.polynomial_coeff[1] * x + lane_line.polynomial_coeff[2], self.test_points)))\n",
        "\n",
        "        dist = np.absolute(test_y_smooth - test_y_new)\n",
        "\n",
        "        #dist = np.absolute(self.smoothed_poly - lane_line.polynomial_coeff)\n",
        "        #dist_max = np.absolute(self.smoothed_poly * self.poly_max_deviation_distance)\n",
        "        max_dist = dist[np.argmax(dist)]\n",
        "\n",
        "        if max_dist > self.poly_max_deviation_distance:\n",
        "            print(\"**** MAX DISTANCE BREACHED ****\")\n",
        "            print(\"y_smooth={0} - y_new={1} - distance={2} - max-distance={3}\".format(test_y_smooth, test_y_new, max_dist, self.poly_max_deviation_distance))\n",
        "            return False\n",
        "\n",
        "        self.lane_lines.append(lane_line)\n",
        "        self.get_smoothed_polynomial()\n",
        "\n",
        "        return True\n",
        "\n",
        "    def get_smoothed_polynomial(self):\n",
        "        all_coeffs = np.asarray(list(map(lambda lane_line: lane_line.polynomial_coeff, self.lane_lines)))\n",
        "        self.smoothed_poly = np.mean(all_coeffs, axis=0)\n",
        "\n",
        "        return self.smoothed_poly\n",
        "\n",
        "\n",
        "def create_queue(length = 10):\n",
        "    return deque(maxlen=length)\n",
        "class LaneLine:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.polynomial_coeff = None\n",
        "        self.line_fit_x = None\n",
        "        self.non_zero_x = []\n",
        "        self.non_zero_y = []\n",
        "        self.windows = []\n",
        "class AdvancedLaneDetectorWithMemory:\n",
        "    \"\"\"\n",
        "    The AdvancedLaneDetectorWithMemory is a class that can detect lines on the road\n",
        "    \"\"\"\n",
        "    def __init__(self, psp_src, psp_dst, sliding_windows_per_line,\n",
        "                 sliding_window_half_width, sliding_window_recenter_thres,\n",
        "                 small_img_size=(256, 144), small_img_x_offset=20, small_img_y_offset=10,\n",
        "                 img_dimensions=(720, 1280), lane_width_px=800,\n",
        "                 lane_center_px_psp=600, real_world_lane_size_meters=(32, 3.7)):\n",
        "        (self.M_psp, self.M_inv_psp) = compute_perspective_transform_matrices(psp_src, psp_dst)\n",
        "\n",
        "        self.sliding_windows_per_line = sliding_windows_per_line\n",
        "        self.sliding_window_half_width = sliding_window_half_width\n",
        "        self.sliding_window_recenter_thres = sliding_window_recenter_thres\n",
        "\n",
        "        self.small_img_size = small_img_size\n",
        "        self.small_img_x_offset = small_img_x_offset\n",
        "        self.small_img_y_offset = small_img_y_offset\n",
        "\n",
        "        self.img_dimensions = img_dimensions\n",
        "        self.lane_width_px = lane_width_px\n",
        "        self.lane_center_px_psp = lane_center_px_psp\n",
        "        self.real_world_lane_size_meters = real_world_lane_size_meters\n",
        "\n",
        "        # We can pre-compute some data here\n",
        "        self.ym_per_px = self.real_world_lane_size_meters[0] / self.img_dimensions[0]\n",
        "        self.xm_per_px = self.real_world_lane_size_meters[1] / self.lane_width_px\n",
        "        self.ploty = np.linspace(0, self.img_dimensions[0] - 1, self.img_dimensions[0])\n",
        "\n",
        "        self.previous_left_lane_line = None\n",
        "        self.previous_right_lane_line = None\n",
        "\n",
        "        self.previous_left_lane_lines = LaneLineHistory()\n",
        "        self.previous_right_lane_lines = LaneLineHistory()\n",
        "\n",
        "        self.total_img_count = 0\n",
        "\n",
        "\n",
        "    def process_image(self, img):\n",
        "        \"\"\"\n",
        "        Attempts to find lane lines on the given image and returns an image with lane area colored in green\n",
        "        as well as small intermediate images overlaid on top to understand how the algorithm is performing\n",
        "        \"\"\"\n",
        "        # First step - undistort the image using the instance's object and image points\n",
        "\n",
        "\n",
        "        # Produce binary thresholded image from color and gradients\n",
        "        thres_img = get_combined_binary_thresholded_img(img)\n",
        "\n",
        "\n",
        "        # Create the undistorted and binary perspective transforms\n",
        "        img_size = (img.shape[1], img.shape[0])\n",
        "        undist_img_psp = cv2.warpPerspective(img, self.M_psp, img_size, flags=cv2.INTER_LINEAR)\n",
        "        thres_img_psp = cv2.warpPerspective(thres_img, self.M_psp, img_size, flags=cv2.INTER_LINEAR)\n",
        "\n",
        "        ll, rl = self.compute_lane_lines(thres_img_psp)\n",
        "        lcr, rcr, lco = self.compute_lane_curvature(ll, rl)\n",
        "\n",
        "        drawn_lines = self.draw_lane_lines(thres_img_psp, ll, rl)\n",
        "\n",
        "        drawn_lines_regions = self.draw_lane_lines_regions(thres_img_psp, ll, rl)\n",
        "\n",
        "        drawn_lane_area = self.draw_lane_area(thres_img_psp, img, ll, rl)\n",
        "\n",
        "        drawn_hotspots = self.draw_lines_hotspots(thres_img_psp, ll, rl)\n",
        "\n",
        "        combined_lane_img = self.combine_images(drawn_lane_area, drawn_lines, drawn_lines_regions, drawn_hotspots, undist_img_psp)\n",
        "\n",
        "        final_img = self.draw_lane_curvature_text(combined_lane_img, lcr, rcr, lco)\n",
        "\n",
        "        self.total_img_count += 1\n",
        "        self.previous_left_lane_line = ll\n",
        "        self.previous_right_lane_line = rl\n",
        "        print(lcr, rcr, lco)\n",
        "        if -0.1 < lco and lco < 0.1:\n",
        "          print('around center')\n",
        "        elif lco < 0:\n",
        "          print('move right by :', lco,'m')\n",
        "        elif lco > 0:\n",
        "          print('move left by :', lco,'m')\n",
        "        # return undist_img_psp\n",
        "        return final_img\n",
        "\n",
        "    def draw_lane_curvature_text(self, img, left_curvature_meters, right_curvature_meters, center_offset_meters):\n",
        "        \"\"\"\n",
        "        Returns an image with curvature information inscribed\n",
        "        \"\"\"\n",
        "\n",
        "        offset_y = self.small_img_size[1] * 1 + self.small_img_y_offset * 5\n",
        "        offset_x = self.small_img_x_offset\n",
        "\n",
        "        template = \"{0:17}{1:17}{2:17}\"\n",
        "        txt_header = template.format(\"Left Curvature\", \"Right Curvature\", \"Center Alignment\")\n",
        "        print(txt_header)\n",
        "        txt_values = template.format(\"{:.4f}m\".format(left_curvature_meters),\n",
        "                                     \"{:.4f}m\".format(right_curvature_meters),\n",
        "                                     \"{:.4f}m Right\".format(center_offset_meters))\n",
        "        if center_offset_meters < 0.0:\n",
        "            txt_values = template.format(\"{:.4f}m\".format(left_curvature_meters),\n",
        "                                     \"{:.4f}m\".format(right_curvature_meters),\n",
        "                                     \"{:.4f}m Left\".format(math.fabs(center_offset_meters)))\n",
        "\n",
        "\n",
        "        print(txt_values)\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        cv2.putText(img, txt_header, (offset_x, offset_y), font, 1, (255,255,255), 1, cv2.LINE_AA)\n",
        "        cv2.putText(img, txt_values, (offset_x, offset_y + self.small_img_y_offset * 5), font, 1, (255,255,255), 2, cv2.LINE_AA)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def combine_images(self, lane_area_img, lines_img, lines_regions_img, lane_hotspots_img, psp_color_img):\n",
        "        \"\"\"\n",
        "        Returns a new image made up of the lane area image, and the remaining lane images are overlaid as\n",
        "        small images in a row at the top of the the new image\n",
        "        \"\"\"\n",
        "        small_lines = cv2.resize(lines_img, self.small_img_size)\n",
        "        small_region = cv2.resize(lines_regions_img, self.small_img_size)\n",
        "        small_hotspots = cv2.resize(lane_hotspots_img, self.small_img_size)\n",
        "        small_color_psp = cv2.resize(psp_color_img, self.small_img_size)\n",
        "\n",
        "        lane_area_img[self.small_img_y_offset: self.small_img_y_offset + self.small_img_size[1], self.small_img_x_offset: self.small_img_x_offset + self.small_img_size[0]] = small_lines\n",
        "\n",
        "        start_offset_y = self.small_img_y_offset\n",
        "        start_offset_x = 2 * self.small_img_x_offset + self.small_img_size[0]\n",
        "        lane_area_img[start_offset_y: start_offset_y + self.small_img_size[1], start_offset_x: start_offset_x + self.small_img_size[0]] = small_region\n",
        "\n",
        "        start_offset_y = self.small_img_y_offset\n",
        "        start_offset_x = 3 * self.small_img_x_offset + 2 * self.small_img_size[0]\n",
        "        lane_area_img[start_offset_y: start_offset_y + self.small_img_size[1], start_offset_x: start_offset_x + self.small_img_size[0]] = small_hotspots\n",
        "\n",
        "        start_offset_y = self.small_img_y_offset\n",
        "        start_offset_x = 4 * self.small_img_x_offset + 3 * self.small_img_size[0]\n",
        "        lane_area_img[start_offset_y: start_offset_y + self.small_img_size[1], start_offset_x: start_offset_x + self.small_img_size[0]] = small_color_psp\n",
        "\n",
        "\n",
        "        return lane_area_img\n",
        "\n",
        "\n",
        "    def draw_lane_area(self, warped_img, img, left_line, right_line):\n",
        "        \"\"\"\n",
        "        Returns an image where the inside of the lane has been colored in bright green\n",
        "        \"\"\"\n",
        "        # Create an image to draw the lines on\n",
        "        warp_zero = np.zeros_like(warped_img).astype(np.uint8)\n",
        "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
        "\n",
        "        ploty = np.linspace(0, warped_img.shape[0] - 1, warped_img.shape[0])\n",
        "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
        "        pts_left = np.array([np.transpose(np.vstack([left_line.line_fit_x, ploty]))])\n",
        "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_line.line_fit_x, ploty])))])\n",
        "        pts = np.hstack((pts_left, pts_right))\n",
        "\n",
        "        # Draw the lane onto the warped blank image\n",
        "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
        "\n",
        "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
        "        newwarp = cv2.warpPerspective(color_warp, self.M_inv_psp, (img.shape[1], img.shape[0]))\n",
        "        # Combine the result with the original image\n",
        "        result = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "    def draw_lane_lines(self, warped_img, left_line, right_line):\n",
        "        \"\"\"\n",
        "        Returns an image where the computed lane lines have been drawn on top of the original warped binary image\n",
        "        \"\"\"\n",
        "        # Create an output image with 3 colors (RGB) from the binary warped image to draw on and  visualize the result\n",
        "        out_img = np.dstack((warped_img, warped_img, warped_img))*255\n",
        "\n",
        "        # Now draw the lines\n",
        "        ploty = np.linspace(0, warped_img.shape[0] - 1, warped_img.shape[0])\n",
        "        pts_left = np.dstack((left_line.line_fit_x, ploty)).astype(np.int32)\n",
        "        pts_right = np.dstack((right_line.line_fit_x, ploty)).astype(np.int32)\n",
        "\n",
        "        cv2.polylines(out_img, pts_left, False,  (255, 140,0), 5)\n",
        "        cv2.polylines(out_img, pts_right, False, (255, 140,0), 5)\n",
        "\n",
        "        for low_pt, high_pt in left_line.windows:\n",
        "            cv2.rectangle(out_img, low_pt, high_pt, (0, 255, 0), 3)\n",
        "\n",
        "        for low_pt, high_pt in right_line.windows:\n",
        "            cv2.rectangle(out_img, low_pt, high_pt, (0, 255, 0), 3)\n",
        "\n",
        "        return out_img\n",
        "\n",
        "    def draw_lane_lines_regions(self, warped_img, left_line, right_line):\n",
        "        \"\"\"\n",
        "        Returns an image where the computed left and right lane areas have been drawn on top of the original warped binary image\n",
        "        \"\"\"\n",
        "        # Generate a polygon to illustrate the search window area\n",
        "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
        "        margin = self.sliding_window_half_width\n",
        "        ploty = np.linspace(0, warped_img.shape[0] - 1, warped_img.shape[0])\n",
        "\n",
        "        left_line_window1 = np.array([np.transpose(np.vstack([left_line.line_fit_x - margin, ploty]))])\n",
        "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_line.line_fit_x + margin,\n",
        "                                      ploty])))])\n",
        "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
        "\n",
        "        right_line_window1 = np.array([np.transpose(np.vstack([right_line.line_fit_x - margin, ploty]))])\n",
        "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_line.line_fit_x + margin,\n",
        "                                      ploty])))])\n",
        "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
        "\n",
        "        # Create RGB image from binary warped image\n",
        "        region_img = np.dstack((warped_img, warped_img, warped_img)) * 255\n",
        "\n",
        "        # Draw the lane onto the warped blank image\n",
        "        cv2.fillPoly(region_img, np.int_([left_line_pts]), (0, 255, 0))\n",
        "        cv2.fillPoly(region_img, np.int_([right_line_pts]), (0, 255, 0))\n",
        "\n",
        "        return region_img\n",
        "\n",
        "\n",
        "    def draw_lines_hotspots(self, warped_img, left_line, right_line):\n",
        "        \"\"\"\n",
        "        Returns a RGB image where the portions of the lane lines that were\n",
        "        identified by our pipeline are colored in yellow (left) and blue (right)\n",
        "        \"\"\"\n",
        "        out_img = np.dstack((warped_img, warped_img, warped_img))*255\n",
        "\n",
        "        out_img[left_line.non_zero_y, left_line.non_zero_x] = [255, 255, 0]\n",
        "        out_img[right_line.non_zero_y, right_line.non_zero_x] = [0, 0, 255]\n",
        "\n",
        "        return out_img\n",
        "\n",
        "    def compute_lane_curvature(self, left_line, right_line):\n",
        "        \"\"\"\n",
        "        Returns the triple (left_curvature, right_curvature, lane_center_offset), which are all in meters\n",
        "        \"\"\"\n",
        "        ploty = self.ploty\n",
        "        y_eval = np.max(ploty)\n",
        "        # Define conversions in x and y from pixels space to meters\n",
        "\n",
        "        leftx = left_line.line_fit_x\n",
        "        rightx = right_line.line_fit_x\n",
        "\n",
        "        # Fit new polynomials: find x for y in real-world space\n",
        "        print(\"Shape of ploty:\", ploty.shape)\n",
        "        print(\"Shape of leftx:\", leftx.shape)\n",
        "        print(\"Shape of rightx:\", rightx.shape)\n",
        "        left_fit_cr = np.polyfit(ploty * self.ym_per_px, leftx * self.xm_per_px, 2)\n",
        "        right_fit_cr = np.polyfit(ploty * self.ym_per_px, rightx * self.xm_per_px, 2)\n",
        "\n",
        "        # Now calculate the radii of the curvature\n",
        "        left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * self.ym_per_px + left_fit_cr[1])**2)**1.5) / np.absolute(2 * left_fit_cr[0])\n",
        "        right_curverad = ((1 + (2 *right_fit_cr[0] * y_eval * self.ym_per_px + right_fit_cr[1])**2)**1.5) / np.absolute(2 * right_fit_cr[0])\n",
        "\n",
        "        # Use our computed polynomial to determine the car's center position in image space, then\n",
        "        left_fit = left_line.polynomial_coeff\n",
        "        right_fit = right_line.polynomial_coeff\n",
        "\n",
        "        center_offset_img_space = (((left_fit[0] * y_eval**2 + left_fit[1] * y_eval + left_fit[2]) +\n",
        "                   (right_fit[0] * y_eval**2 + right_fit[1] * y_eval + right_fit[2])) / 2) - self.lane_center_px_psp\n",
        "        center_offset_real_world_m = center_offset_img_space * self.xm_per_px\n",
        "\n",
        "        # Now our radius of curvature is in meters\n",
        "        return left_curverad, right_curverad, center_offset_real_world_m\n",
        "\n",
        "\n",
        "\n",
        "    def compute_lane_lines(self, warped_img):\n",
        "        \"\"\"\n",
        "        Returns the tuple (left_lane_line, right_lane_line) which represents respectively the LaneLine instances for\n",
        "        the computed left and right lanes, for the supplied binary warped image\n",
        "        \"\"\"\n",
        "\n",
        "        # Take a histogram of the bottom half of the image, summing pixel values column wise\n",
        "        histogram = np.sum(warped_img[warped_img.shape[0]//2:,:], axis=0)\n",
        "\n",
        "        # Smooth the histogram\n",
        "        kernel_width = 5\n",
        "        smoothing_kernel = np.ones(kernel_width) / kernel_width\n",
        "\n",
        "        # Apply convolution to smooth the histogram\n",
        "        smoothed_histogram = np.convolve(histogram, smoothing_kernel, mode='same')\n",
        "\n",
        "        # Find the peak of the left and right halves of the histogram\n",
        "        # These will be the starting point for the left and right lines\n",
        "        midpoint = np.int(smoothed_histogram.shape[0]//2)\n",
        "        leftx_base = np.argmax(smoothed_histogram[:midpoint])\n",
        "        rightx_base = np.argmax(smoothed_histogram[midpoint:]) + midpoint # don't forget to offset by midpoint!\n",
        "\n",
        "\n",
        "        # Set height of windows\n",
        "        window_height = np.int(warped_img.shape[0]//self.sliding_windows_per_line)\n",
        "        # Identify the x and y positions of all nonzero pixels in the image\n",
        "        # NOTE: nonzero returns a tuple of arrays in y and x directions\n",
        "        nonzero = warped_img.nonzero()\n",
        "        nonzeroy = np.array(nonzero[0])\n",
        "        nonzerox = np.array(nonzero[1])\n",
        "\n",
        "        total_non_zeros = len(nonzeroy)\n",
        "        non_zero_found_pct = 0.0\n",
        "\n",
        "        # Current positions to be updated for each window\n",
        "        leftx_current = leftx_base\n",
        "        rightx_current = rightx_base\n",
        "\n",
        "\n",
        "        # Set the width of the windows +/- margin\n",
        "        margin = self.sliding_window_half_width\n",
        "        # Set minimum number of pixels found to recenter window\n",
        "        minpix = self.sliding_window_recenter_thres\n",
        "        # Create empty lists to receive left and right lane pixel indices\n",
        "        left_lane_inds = []\n",
        "        right_lane_inds = []\n",
        "\n",
        "        # Our lane line objects we store the result of this computation\n",
        "        left_line = LaneLine()\n",
        "        right_line = LaneLine()\n",
        "\n",
        "        if self.previous_left_lane_line is not None and self.previous_right_lane_line is not None:\n",
        "            # We have already computed the lane lines polynomials from a previous image\n",
        "            left_lane_inds = ((nonzerox > (self.previous_left_lane_line.polynomial_coeff[0] * (nonzeroy**2)\n",
        "                                           + self.previous_left_lane_line.polynomial_coeff[1] * nonzeroy\n",
        "                                           + self.previous_left_lane_line.polynomial_coeff[2] - margin))\n",
        "                              & (nonzerox < (self.previous_left_lane_line.polynomial_coeff[0] * (nonzeroy**2)\n",
        "                                            + self.previous_left_lane_line.polynomial_coeff[1] * nonzeroy\n",
        "                                            + self.previous_left_lane_line.polynomial_coeff[2] + margin)))\n",
        "\n",
        "            right_lane_inds = ((nonzerox > (self.previous_right_lane_line.polynomial_coeff[0] * (nonzeroy**2)\n",
        "                                           + self.previous_right_lane_line.polynomial_coeff[1] * nonzeroy\n",
        "                                           + self.previous_right_lane_line.polynomial_coeff[2] - margin))\n",
        "                              & (nonzerox < (self.previous_right_lane_line.polynomial_coeff[0] * (nonzeroy**2)\n",
        "                                            + self.previous_right_lane_line.polynomial_coeff[1] * nonzeroy\n",
        "                                            + self.previous_right_lane_line.polynomial_coeff[2] + margin)))\n",
        "\n",
        "            non_zero_found_left = np.sum(left_lane_inds)\n",
        "            non_zero_found_right = np.sum(right_lane_inds)\n",
        "            non_zero_found_pct = (non_zero_found_left + non_zero_found_right) / total_non_zeros\n",
        "\n",
        "            print(\"[Previous lane] Found pct={0}\".format(non_zero_found_pct))\n",
        "\n",
        "        if non_zero_found_pct < 0.85:\n",
        "            print(\"Non zeros found below thresholds, begining sliding window - pct={0}\".format(non_zero_found_pct))\n",
        "            left_lane_inds = []\n",
        "            right_lane_inds = []\n",
        "\n",
        "            # Step through the windows one by one\n",
        "            for window in range(self.sliding_windows_per_line):\n",
        "                # Identify window boundaries in x and y (and right and left)\n",
        "                # We are moving our windows from the bottom to the top of the screen (highest to lowest y value)\n",
        "                win_y_low = warped_img.shape[0] - (window + 1)* window_height\n",
        "                win_y_high = warped_img.shape[0] - window * window_height\n",
        "\n",
        "                # Defining our window's coverage in the horizontal (i.e. x) direction\n",
        "                # Notice that the window's width is twice the margin\n",
        "                win_xleft_low = leftx_current - margin\n",
        "                win_xleft_high = leftx_current + margin\n",
        "                win_xright_low = rightx_current - margin\n",
        "                win_xright_high = rightx_current + margin\n",
        "\n",
        "                left_line.windows.append([(win_xleft_low,win_y_low),(win_xleft_high,win_y_high)])\n",
        "                right_line.windows.append([(win_xright_low,win_y_low),(win_xright_high,win_y_high)])\n",
        "\n",
        "                # Super crytic and hard to understand...\n",
        "                # Basically nonzerox and nonzeroy have the same size and any nonzero pixel is identified by\n",
        "                # (nonzeroy[i],nonzerox[i]), therefore we just return the i indices within the window that are nonzero\n",
        "                # and can then index into nonzeroy and nonzerox to find the ACTUAL pixel coordinates that are not zero\n",
        "                good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "                (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
        "                good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "                (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
        "\n",
        "                # Append these indices to the lists\n",
        "                left_lane_inds.append(good_left_inds)\n",
        "                right_lane_inds.append(good_right_inds)\n",
        "\n",
        "                # If you found > minpix pixels, recenter next window on their mean position\n",
        "                if len(good_left_inds) > minpix:\n",
        "                    leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
        "                if len(good_right_inds) > minpix:\n",
        "                    rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
        "\n",
        "            # Concatenate the arrays of indices since we now have a list of multiple arrays (e.g. ([1,3,6],[8,5,2]))\n",
        "            # We want to create a single array with elements from all those lists (e.g. [1,3,6,8,5,2])\n",
        "            # These are the indices that are non zero in our sliding windows\n",
        "            left_lane_inds = np.concatenate(left_lane_inds)\n",
        "            right_lane_inds = np.concatenate(right_lane_inds)\n",
        "\n",
        "            non_zero_found_left = np.sum(left_lane_inds)\n",
        "            non_zero_found_right = np.sum(right_lane_inds)\n",
        "            non_zero_found_pct = (non_zero_found_left + non_zero_found_right) / total_non_zeros\n",
        "\n",
        "            print(\"[Sliding windows] Found pct={0}\".format(non_zero_found_pct))\n",
        "\n",
        "\n",
        "        # Extract left and right line pixel positions\n",
        "        leftx = nonzerox[left_lane_inds]\n",
        "        lefty = nonzeroy[left_lane_inds]\n",
        "        rightx = nonzerox[right_lane_inds]\n",
        "        righty = nonzeroy[right_lane_inds]\n",
        "\n",
        "        #print(\"[LEFT] Number of hot pixels={0}\".format(len(leftx)))\n",
        "        #print(\"[RIGHT] Number of hot pixels={0}\".format(len(rightx)))\n",
        "        # Fit a second order polynomial to each\n",
        "        left_fit = np.polyfit(lefty, leftx, 2)\n",
        "        right_fit = np.polyfit(righty, rightx, 2)\n",
        "        #print(\"Poly left {0}\".format(left_fit))\n",
        "        #print(\"Poly right {0}\".format(right_fit))\n",
        "        left_line.polynomial_coeff = left_fit\n",
        "        right_line.polynomial_coeff = right_fit\n",
        "\n",
        "        if not self.previous_left_lane_lines.append(left_line):\n",
        "            left_fit = self.previous_left_lane_lines.get_smoothed_polynomial()\n",
        "            left_line.polynomial_coeff = left_fit\n",
        "            self.previous_left_lane_lines.append(left_line, force=True)\n",
        "            print(\"**** REVISED Poly left {0}\".format(left_fit))\n",
        "        #else:\n",
        "            #left_fit = self.previous_left_lane_lines.get_smoothed_polynomial()\n",
        "            #left_line.polynomial_coeff = left_fit\n",
        "\n",
        "\n",
        "        if not self.previous_right_lane_lines.append(right_line):\n",
        "            right_fit = self.previous_right_lane_lines.get_smoothed_polynomial()\n",
        "            right_line.polynomial_coeff = right_fit\n",
        "            self.previous_right_lane_lines.append(right_line, force=True)\n",
        "            print(\"**** REVISED Poly right {0}\".format(right_fit))\n",
        "        #else:\n",
        "            #right_fit = self.previous_right_lane_lines.get_smoothed_polynomial()\n",
        "            #right_line.polynomial_coeff = right_fit\n",
        "\n",
        "\n",
        "\n",
        "        # Generate x and y values for plotting\n",
        "        ploty = np.linspace(0, warped_img.shape[0] - 1, warped_img.shape[0] )\n",
        "        left_fitx = left_fit[0] * ploty**2 + left_fit[1] * ploty + left_fit[2]\n",
        "        right_fitx = right_fit[0] * ploty**2 + right_fit[1] * ploty + right_fit[2]\n",
        "\n",
        "\n",
        "        left_line.polynomial_coeff = left_fit\n",
        "        left_line.line_fit_x = left_fitx\n",
        "        left_line.non_zero_x = leftx\n",
        "        left_line.non_zero_y = lefty\n",
        "\n",
        "        right_line.polynomial_coeff = right_fit\n",
        "        right_line.line_fit_x = right_fitx\n",
        "        right_line.non_zero_x = rightx\n",
        "        right_line.non_zero_y = righty\n",
        "\n",
        "\n",
        "        return (left_line, right_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "Qy3RHTx5HZQB",
        "outputId": "d8e1124e-460f-4cc5-9847-da0a4c2f30d7"
      },
      "outputs": [],
      "source": [
        "test_img = test_imgs[4]\n",
        "\n",
        "# Scale perspective to size of test inage\n",
        "ctrlx = 1042\n",
        "ctrly = 590\n",
        "x_dim = test_img.shape[1]\n",
        "y_dim = test_img.shape[0]\n",
        "bottom_px = y_dim - 1\n",
        "right_px = x_dim - 1\n",
        "pts = np.array([[25*x_dim/ctrlx,430*y_dim/ctrly],[375*x_dim/ctrlx,345*y_dim/ctrly],[660*x_dim/ctrlx,345*y_dim/ctrly], [(right_px-20)*x_dim/ctrlx, 420*y_dim/ctrly]], np.int32)\n",
        "src_pts = pts.astype(np.float32)\n",
        "dst_pts = np.array([[200, bottom_px], [200, 0], [right_px-200, 0], [right_px-200, bottom_px]], np.float32)\n",
        "# ^ May need to alter dst_pts\n",
        "\n",
        "ld = AdvancedLaneDetectorWithMemory(src_pts, dst_pts, 20, 200, 50, img_dimensions=(y_dim,x_dim),real_world_lane_size_meters=(2.1,1.05),small_img_size=(128,72))\n",
        "proc_img = ld.process_image(test_img)\n",
        "plt.imshow(proc_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ok3zIbrOw25l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
